{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tUhhAgMMYQf7"
      },
      "outputs": [],
      "source": [
        "#@title Run on TensorFlow 2.x\n",
        "%tensorflow_version 2.x\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TF5ZxEdGYT5M"
      },
      "outputs": [],
      "source": [
        "#@title Import relevant modules\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import cv2\n",
        "# import os\n",
        "# import shutil\n",
        "# import random\n",
        "# import glob\n",
        "from matplotlib import pyplot as plt\n",
        "# import warnings\n",
        "# import seaborn as sns\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lG7UOC5vYUNw"
      },
      "outputs": [],
      "source": [
        "#set paths \n",
        "train_path = '/Users/jeremystubbs/Desktop/googledata_cats_and_dogs/train'\n",
        "valid_path = '/Users/jeremystubbs/Desktop/googledata_cats_and_dogs/validation'\n",
        "test_path = '/Users/jeremystubbs/Desktop/googledata_cats_and_dogs/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ifp5tAcq-FyH"
      },
      "outputs": [],
      "source": [
        "def plotImages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 10, figsize = (20,20))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8unlx8ePAMIE"
      },
      "source": [
        "Import the pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXDmkNIs9s_-",
        "outputId": "f13110da-60b1-47a8-cf13-ecb8e7dcdb97"
      },
      "outputs": [],
      "source": [
        "vgg16_model = tf.keras.applications.vgg16.VGG16()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q0Srmlt2ALj3"
      },
      "outputs": [],
      "source": [
        "vgg16_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZoK60v3hAXs9"
      },
      "outputs": [],
      "source": [
        "# Create sequential model with layers set to layers of vgg16\n",
        "model = keras.Sequential()\n",
        "for layer in vgg16_model.layers[:-1]:\n",
        "  model.add(layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "E_IfUxvFCHGG"
      },
      "outputs": [],
      "source": [
        "# Prevent alteration of model\n",
        "for layer in model.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JhJNZ5imCdaf"
      },
      "outputs": [],
      "source": [
        "# add output layer\n",
        "model.add(layers.Dense(units=2, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "fuc34YXdCfvL"
      },
      "outputs": [],
      "source": [
        "# compile model\n",
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKBWI-q4XYoA",
        "outputId": "4a4f4268-0596-439c-b667-d6dce83fa656"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 1000 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "# # \n",
        "BATCH_SIZE = 10\n",
        "IMG_SIZE=(224,224)\n",
        "train_dataset = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=train_path, target_size=(224,224), classes=['cats','dogs'], batch_size=10)\n",
        "validation_dataset = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=valid_path, target_size=(224,224), classes=['cats','dogs'], batch_size=10)\n",
        "# test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input).flow_from_directory(directory=test_path, classes=None, target_size=(224,224), batch_size=10, shuffle=False)\n",
        "\n",
        "\n",
        "# train_dataset = tf.keras.utils.image_dataset_from_directory(train_path,\n",
        "#                                                             shuffle=True,\n",
        "#                                                             batch_size=BATCH_SIZE,\n",
        "#                                                             image_size=IMG_SIZE)\n",
        "\n",
        "# validation_dataset = tf.keras.utils.image_dataset_from_directory(valid_path,\n",
        "#                                                                  shuffle=True,\n",
        "#                                                                  batch_size=BATCH_SIZE,\n",
        "#                                                                  image_size=IMG_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hNTHGVnJCf4C",
        "outputId": "f0ffaf4e-9277-46f0-854b-545f11ebe698"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-04-27 08:15:02.101396: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "100/100 [==============================] - 185s 2s/step - loss: 0.3929 - accuracy: 0.8330 - val_loss: 0.1218 - val_accuracy: 0.9650\n",
            "Epoch 2/5\n",
            "100/100 [==============================] - 188s 2s/step - loss: 0.1095 - accuracy: 0.9600 - val_loss: 0.0835 - val_accuracy: 0.9800\n",
            "Epoch 3/5\n",
            "100/100 [==============================] - 200s 2s/step - loss: 0.0801 - accuracy: 0.9770 - val_loss: 0.0571 - val_accuracy: 0.9800\n",
            "Epoch 4/5\n",
            "100/100 [==============================] - 190s 2s/step - loss: 0.0611 - accuracy: 0.9820 - val_loss: 0.0761 - val_accuracy: 0.9750\n",
            "Epoch 5/5\n",
            "100/100 [==============================] - 241s 2s/step - loss: 0.0589 - accuracy: 0.9830 - val_loss: 0.0953 - val_accuracy: 0.9650\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1567c4f70>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit model\n",
        "model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=100,\n",
        "        epochs=5,\n",
        "        validation_data=validation_dataset,\n",
        "        validation_steps=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06o8k4ntxVOY",
        "outputId": "27980a15-f96f-4111-e2cb-f41b74aeec8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (1, 224, 224, 3)\n"
          ]
        }
      ],
      "source": [
        "# Predict images in test set with model \n",
        "img = cv2.imread(\"dog2.jpg\")\n",
        "resized = cv2.resize(img, (224, 224))\n",
        "reshaped = resized.reshape(1, 224, 224, 3)\n",
        "print(type(reshaped), reshaped.shape)\n",
        "\n",
        "\n",
        "# tf.keras.applications.vgg16.preprocess_input(img)\n",
        "predictions = model.predict(reshaped, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm4gSblcHwqJ",
        "outputId": "84f21a4f-7d0a-49da-f627-9d9681db2be8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7.706941e-05 9.999229e-01]]\n"
          ]
        }
      ],
      "source": [
        "print(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1WkLtRzHw6h",
        "outputId": "c376e4bb-9b67-48f0-adab-31bb6eb25286"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "x = []\n",
        "for i in range(len(predictions)):\n",
        "  if predictions[i][0]>=predictions[i][1]:\n",
        "    x.append(0)\n",
        "  else:\n",
        "    x.append(1)\n",
        "answers = np.array(x)\n",
        "answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "2ShX8z9UHxF_",
        "outputId": "fe01db8e-607c-4235-e124-5200804737f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f1f18bfbe90>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "cm = confusion_matrix(test_batches.classes, answers)\n",
        "disp = ConfusionMatrixDisplay(cm)\n",
        "disp.plot()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "vgg16_cats_dogs.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
